{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTROY = 'data'\n",
    "MODEL_PATH = 'models'\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(a):\n",
    "    w, h = a.size\n",
    "    if w < h:\n",
    "        scale = h/IMG_SIZE\n",
    "        w = int(w/scale)\n",
    "        h = IMG_SIZE\n",
    "        a = a.resize((w, h))\n",
    "        lb= np.array([a.load()[0,x] for x in range(h)])\n",
    "        rb = np.array([a.load()[w-1,x] for x in range(h)])\n",
    "        lb = lb.mean(axis=0).astype('uint8')\n",
    "        rb = rb.mean(axis=0).astype('uint8')\n",
    "        pic = Image.new('RGB', (h, h), color = (255, 255, 255))\n",
    "        imgl = Image.new('RGB', (h//2, h), color = tuple(lb))\n",
    "        imgr = Image.new('RGB', (h//2, h), color = tuple(rb))\n",
    "        \n",
    "        pic.paste(imgl, (0, 0))\n",
    "        pic.paste(imgr, (h//2, 0))\n",
    "        \n",
    "        pic.paste(a, (h//2-w//2, 0))\n",
    "\n",
    "    elif w>h:\n",
    "        scale = w/IMG_SIZE\n",
    "        h = int(h/scale)\n",
    "        w = IMG_SIZE\n",
    "        a = a.resize((w, h))\n",
    "        \n",
    "        lb= np.array([a.load()[x,0] for x in range(w)])\n",
    "        rb = np.array([a.load()[x,h-1] for x in range(w)])\n",
    "        lb = lb.mean(axis=0).astype('uint8')\n",
    "        rb = rb.mean(axis=0).astype('uint8')\n",
    "        \n",
    "        pic = Image.new('RGB', (w, w), color = (255, 255, 255))\n",
    "        imgl = Image.new('RGB', (w, w//2), color = tuple(lb))\n",
    "        imgr = Image.new('RGB', (w, w//2), color = tuple(rb))\n",
    "        \n",
    "        pic.paste(imgl, (0, 0))\n",
    "        pic.paste(imgr, (0, w//2))\n",
    "        \n",
    "        pic.paste(a, (0, w//2-h//2))\n",
    "\n",
    "    else:\n",
    "        a = a.resize((IMG_SIZE, IMG_SIZE))\n",
    "        pic = a\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change image in following methods\n",
    "\n",
    "- Vertical flip\n",
    "- Horizontal flip\n",
    "- Rotate 30 degree\n",
    "- Zoom\n",
    "- Random noise\n",
    "- Random blocks cover the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{DIRECTROY}/reduced_train.csv') \n",
    "df_test = pd.read_csv(f'{DIRECTROY}/reduced_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image_vertical(image):\n",
    "    return np.fliplr(image)\n",
    "\n",
    "def flip_image_horizontal(image):\n",
    "    return np.flipud(image)\n",
    "\n",
    "def rotate_image(image, angle=30):\n",
    "    return image.rotate(angle)\n",
    "\n",
    "\n",
    "def randomCrop(im, margin=1.25):\n",
    "    '''\n",
    "    croping the image in the center from a random margin from the borders\n",
    "    '''\n",
    "    mg = int(np.random.rand()*30)\n",
    "    margin -=1\n",
    "    margin/=2\n",
    "    start = [mg + im.size[0]*margin, mg + im.size[0]*margin]\n",
    "    end = [min(mg+ im.size[0] * (1-margin), im.size[0]),  min(mg+im.size[1]*(1-margin), im.size[1])]\n",
    "    cropped_image = im.crop((start[0], start[1], end[0], end[1]))\n",
    "    return cropped_image\n",
    "\n",
    "def add_noise(image):\n",
    "    img =  random_noise(np.array(image))*255\n",
    "    img = Image.fromarray(img.astype('uint8'))\n",
    "    return img\n",
    "\n",
    "def add_random_box(img):\n",
    "    box_width = np.random.randint(20,50)\n",
    "    color = list(np.random.choice(range(256), size=3))\n",
    "    img2 = img.copy()\n",
    "    img2.paste(Image.new('RGB', (box_width, box_width), color = tuple(color)), (np.random.randint(0,IMG_SIZE-box_width), np.random.randint(0,IMG_SIZE-box_width)))\n",
    "    return img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(df,tasks='train'):\n",
    "    for i in range(len(df)):\n",
    "        img = Image.open(f'{DIRECTROY}/{tasks}/{df.iloc[i].name}')\n",
    "        img = resize_img(img)\n",
    "        img.save(f'{DIRECTROY}/resize_{tasks}/{df.iloc[i].name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(df_train, type='horizontal'):\n",
    "    df_aug = df_train.sample(frac=0.245)\n",
    "    images = df_aug['name'].values\n",
    "    # for image in images:\n",
    "    #     im = Image.open(f'{DIRECTROY}/train/{image}')\n",
    "    #     if type == 'horizontal':\n",
    "    #         im = flip_image_horizontal(im)\n",
    "    #     elif type == 'vertical':\n",
    "    #         im = flip_image_vertical(im)\n",
    "    #     elif type == 'rotate':\n",
    "    #         im = resize_img(im)\n",
    "    #         im = rotate_image(im)\n",
    "    #     elif type == 'crop':\n",
    "    #         im = resize_img(im)\n",
    "    #         im = randomCrop(im)\n",
    "    #     elif type == 'noise':\n",
    "    #         im = add_noise(im)\n",
    "    #     elif type == 'box':\n",
    "    #           im = resize_img(im)\n",
    "    #         im = add_random_box(im)\n",
    "    #     im = resize_img(im)\n",
    "    #     im.save(f'{DIRECTROY}/resize_train/{type}_{image}')\n",
    "    \n",
    "    df_aug['name'] = df_aug['name'].apply(lambda x: f'{type}_{x}')\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = augment_image(df_train, type='horizontal')\n",
    "df_v = augment_image(df_train, type='vertical')\n",
    "df_r = augment_image(df_train, type='rotate')\n",
    "df_c = augment_image(df_train, type='crop')\n",
    "df_n = augment_image(df_train, type='noise')\n",
    "df_b = augment_image(df_train, type='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.concat([df_train, df_h, df_v, df_r, df_c, df_n,df_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72233"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29243"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug.sample(frac=1).to_csv(f'{DIRECTROY}/augmented_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader \n",
    "Split dataset to multiple pack due to lack of ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizerFast\n",
    "import torch\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda, Resize, Normalize\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = Compose([\n",
    "    Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transforms, directory):\n",
    "        self.tokenizer =  CLIPTokenizerFast.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.directory = directory\n",
    "        self.labels = torch.Tensor(df['newid'].values).long()\n",
    "        self.imgs = torch.cat([ self.transforms(Image.open(f'{DIRECTROY}/{self.directory}/{x}').convert('RGB')).half().reshape(1,3,IMG_SIZE,IMG_SIZE) for x in tqdm(df['name'].values)])\n",
    "        self.tokenized = self.tokenizer(df['label'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        self.input_ids = self.tokenized['input_ids']\n",
    "        self.attention_mask = self.tokenized['attention_mask']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = self.input_ids[idx]\n",
    "        attention_mask = self.attention_mask[idx]\n",
    "        return img, label, input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(math.ceil(len(df_aug)/36384)):\n",
    "    train_dataset = CustomDataset(df_aug[i*36384:(i+1)*36384], image_transforms, 'train')\n",
    "    torch.save(train_dataset, f'{DIRECTROY}/train_dataset/train_dataset_reduced_aug_{i}.pth')\n",
    "    del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(df_aug[i*36384:(i+1)*36384], image_transforms, 'train')\n",
    "torch.save(test_dataset, f'{DIRECTROY}/test_dataset/train_dataset_reduced_{i}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
