{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda, Resize, Normalize\n",
    "from PIL import Image, ImageDraw\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[MetaFormer](https://arxiv.org/abs/2210.13452)** for Image Classification\n",
    "\n",
    "This notebook will use the best variance of **Metaformer**, **CAFormer** for image classification\n",
    "\n",
    "Original paper: **[MetaFormer Baselines for Vision](https://arxiv.org/abs/2210.13452)**\n",
    "\n",
    "Github: **[MetaFormer](https://github.com/sail-sg/metaformer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTROY = 'data'\n",
    "MODEL_PATH = 'models'\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LR = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{DIRECTROY}/reduced_train.csv') \n",
    "df_test = pd.read_csv(f'{DIRECTROY}/reduced_test.csv') \n",
    "num_classes = len(df_train['newid'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = Compose([\n",
    "    Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transforms, directory):\n",
    "        self.tokenizer =  CLIPTokenizerFast.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.directory = directory\n",
    "        self.labels = torch.Tensor(df['newid'].values).long()\n",
    "        self.imgs = torch.cat([ self.transforms(self.resize_img(Image.open(f'{DIRECTROY}/{self.directory}/{x}')).convert('RGB')).half().reshape(1,3,IMG_SIZE,IMG_SIZE) for x in tqdm(df['name'].values)])\n",
    "        self.tokenized = self.tokenizer(df['label'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        self.input_ids = self.tokenized['input_ids']\n",
    "        self.attention_mask = self.tokenized['attention_mask']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = self.input_ids[idx]\n",
    "        attention_mask = self.attention_mask[idx]\n",
    "        return img, label, input_ids, attention_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CAFormer\n",
    "Model parameters: \n",
    "- Small: 39M\n",
    "- Big: 99M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaFormer(\n",
       "  (downsample_layers): ModuleList(\n",
       "    (0): Downsampling(\n",
       "      (pre_norm): Identity()\n",
       "      (conv): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
       "      (post_norm): LayerNormGeneral()\n",
       "    )\n",
       "    (1): Downsampling(\n",
       "      (pre_norm): LayerNormGeneral()\n",
       "      (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (post_norm): Identity()\n",
       "    )\n",
       "    (2): Downsampling(\n",
       "      (pre_norm): LayerNormGeneral()\n",
       "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (post_norm): Identity()\n",
       "    )\n",
       "    (3): Downsampling(\n",
       "      (pre_norm): LayerNormGeneral()\n",
       "      (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (post_norm): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stages): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=96, out_features=192, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=192, out_features=96, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (1): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=96, out_features=192, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=192, out_features=96, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (2): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=96, out_features=192, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=192, out_features=96, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (1): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (2): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (3): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (4): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (5): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (6): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (7): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (8): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (9): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (10): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "      (11): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): SepConv(\n",
       "          (pwconv1): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (act1): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "          (act2): Identity()\n",
       "          (pwconv2): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Identity()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (1): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (2): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (3): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (4): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (5): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (6): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (7): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (8): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (9): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (10): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (11): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (12): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (13): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (14): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (15): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (16): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (17): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=576, out_features=1728, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=576, out_features=2304, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=2304, out_features=576, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (1): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=576, out_features=1728, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=576, out_features=2304, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=2304, out_features=576, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "      (2): MetaFormerBlock(\n",
       "        (norm1): LayerNormWithoutBias()\n",
       "        (token_mixer): Attention(\n",
       "          (qkv): Linear(in_features=576, out_features=1728, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (layer_scale1): Identity()\n",
       "        (res_scale1): Scale()\n",
       "        (norm2): LayerNormWithoutBias()\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=576, out_features=2304, bias=False)\n",
       "          (act): StarReLU(\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=2304, out_features=576, bias=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "        (layer_scale2): Identity()\n",
       "        (res_scale2): Scale()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): MlpHead(\n",
       "    (fc1): Linear(in_features=576, out_features=2304, bias=True)\n",
       "    (act): SquaredReLU(\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (norm): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc2): Linear(in_features=2304, out_features=1000, bias=True)\n",
       "    (head_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaformer import caformer_s36_in21ft1k, caformer_m36_in21ft1k, caformer_b36_in21ft1k\n",
    "\n",
    "model = caformer_m36_in21ft1k(pretrained=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head.fc2 = nn.Linear(model.head.fc2.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(f'{DIRECTROY}/train_dataset/train_dataset_reduced_all.pth')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=int(BATCH_SIZE/1), shuffle=True)\n",
    "\n",
    "test_dataset = torch.load(f'{DIRECTROY}/test_public_dataset/test_public_reduced_dataset_0.pth')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=int(BATCH_SIZE/1), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    print('Training epoch:', epoch+1)\n",
    "    len_train = 0\n",
    " \n",
    "    \n",
    "\n",
    "    \n",
    "    for inputs, labels, input_ids, attention_mask in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device).type(torch.cuda.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    len_train += len(train_dataset)\n",
    "   \n",
    "        \n",
    "    scheduler.step()    \n",
    "    train_loss/=len_train\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {train_loss}')\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    print('Evaluating epoch:', epoch+1)\n",
    "    with torch.no_grad():\n",
    "        len_test = 0\n",
    "        \n",
    "        \n",
    "        for inputs, labels, input_ids, attention_mask in tqdm(test_dataloader):\n",
    "            inputs = inputs.to(device).type(torch.cuda.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels).to(device)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            outputs = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
    "            labels = labels.flatten().cpu().numpy()\n",
    "            \n",
    "            true_labels.extend(labels)\n",
    "            pred_labels.extend(outputs)\n",
    "        \n",
    "        len_test += len(test_dataset)\n",
    "        \n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {eval_loss/len_test}')\n",
    "    print(f'Accuracy: {accuracy_score(true_labels, pred_labels)}')\n",
    "    print(f'F1 Score Weighted: {f1_score(true_labels, pred_labels, average=\"weighted\")}')\n",
    "    print(f'F1 Score Macro: {f1_score(true_labels, pred_labels, average=\"macro\")}')\n",
    "    if accuracy_score(true_labels, pred_labels) > max_accuracy:\n",
    "        max_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "        torch.save(model.state_dict(), f'{MODEL_PATH}/CAFormer_reduced_model_{epoch+1}.pth')\n",
    "        torch.save(optimizer.state_dict(), f'{MODEL_PATH}/optimizer/CAFormer_vit_reduced_optimizer_{epoch+1}.pth')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000015BEC91F3E0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97674991"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
